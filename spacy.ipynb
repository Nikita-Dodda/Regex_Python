{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/\n",
    "# https://spacy.io/usage\n",
    "# https://spacy.io/models/en\n",
    "# https://spacy.io/api/doc\n",
    "# https://spacy.io/api/token\n",
    "# https://spacy.io/usage/processing-pipelines\n",
    "# https://spacy.io/usage/spacy-101\n",
    "#\n",
    "#  - spaCy is a free, open-source library for advanced industrial-strength Natural Language Processing (NLP) in Python.\n",
    "#\n",
    "# - When you call spaCy on a text, spaCy first tokenizes the text (i.e. segments it into words, punctuation and so on) to produce a Doc object. \n",
    "#    spaCy uses rules specific to each language for tokenization.\n",
    "# \n",
    "#  - The Doc object is then processed in several different steps (also referred to as the processing pipeline). \n",
    "#    The pipeline used by the default models consists of a (pos) tagger, a (dependency) parser and a (named) entity recognizer (ner). \n",
    "#    spaCy uses statistical models to predict pos, syntatctic dependencies, and named entities.\n",
    "#    Each pipeline component returns the processed Doc, which is then passed on to the next component.\n",
    "#    You can pick and choose the stages you want spaCy to load.\n",
    "#\n",
    "# - Here is a list of features and capabilities of spaCy: \n",
    "#   https://spacy.io/usage/spacy-101#features\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### installation #####\n",
    "\n",
    "# https://spacy.io/usage\n",
    "# pip install spacy\n",
    "\n",
    "# https://spacy.io/models/en\n",
    "# you can download these general-purpose pretrained models to predict \n",
    "# pos tags (tagger), named entities (ner), and syntactic dependencies (parser).\n",
    "#     note: n_core_web_sm does not include word-vectors, but en_core_web_md and en_core_web_lg do.\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en_core_web_md\n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# once you’ve downloaded and installed a model, you can load it via spacy.load(). \n",
    "# spacy.load() returns a Language object containing all components and data needed to process text. \\\n",
    "# the Language object is typically called nlp. \n",
    "nlp = spacy.load(\"en_core_web_md\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the nlp object on a string of text will return a processed Doc object. the Doc object is typically called doc.\n",
    "# even though a Doc object is processed (for isntance, split into individual words and annotated),\n",
    "# it still holds all information of the original text.\n",
    "# once the doc object has been created, we can  use it to access the various spaCy features.\n",
    "doc = nlp(\"Hi Emma Watson! How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Emma Watson!\n",
      "How are you?\n"
     ]
    }
   ],
   "source": [
    "# for instance, you can iterate over individual sentences in the document.\n",
    "for s in doc.sents:\n",
    "    print (s.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Watson PERSON People, including fictional\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emma Watson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "! How are you?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can iterate over the named entities in the document (from ner)\n",
    "# a named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title.\n",
    "for e in doc.ents:\n",
    "    print (e.text, e.label_, spacy.explain(e.label_))\n",
    "\n",
    "# you can visualize the named entities \n",
    "spacy.displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"38d923d9bf0a49308c1cc6a90eaabcf5-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Emma</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Watson!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">How</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">you?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-38d923d9bf0a49308c1cc6a90eaabcf5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can also visualize the dependencies (from parser)\n",
    "spacy.displacy.render(doc, style=\"dep\", jupyter= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Emma Watson\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "# you can iterate over the base noun chunks in the document.\n",
    "# noun chunks are “base noun phrases”  - a noun plus the words describing the noun.\n",
    "# for instance, “the lavish green grass” or “the world’s largest tech fund”.\n",
    "for c in doc.noun_chunks:\n",
    "    print (c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hi Hi  None hi INTJ interjection UH interjection compound False False False False True True False False False True False False False\n",
      "1 Emma Emma PERSON People, including fictional Emma PROPN proper noun NNP noun, proper singular compound False False False False True True False False False True False False False\n",
      "2 Watson Watson PERSON People, including fictional Watson PROPN proper noun NNP noun, proper singular ROOT False False False False True True False False False True False False False\n",
      "3 ! !  None ! PUNCT punctuation . punctuation mark, sentence closer punct False False False False False True False False False False True False False\n",
      "4 How How  None how ADV adverb WRB wh-adverb advmod False False False True True True False False False True False False False\n",
      "5 are are  None be AUX auxiliary VBP verb, non-3rd person singular present ROOT False False False True True True False True False False False False False\n",
      "6 you you  None -PRON- PRON pronoun PRP pronoun, personal nsubj False False False True True True False True False False False False False\n",
      "7 ? ?  None ? PUNCT punctuation . punctuation mark, sentence closer punct False False False False False True False False False False True False False\n"
     ]
    }
   ],
   "source": [
    "# you can iterate over the linguisitic annotations associated with tokens in the document (from tagger)\n",
    "# https://spacy.io/api/annotation\n",
    "# https://spacy.io/api/token#attributes\n",
    "doc = nlp(\"Hi Emma Watson! How are you?\")\n",
    "for token in doc:\n",
    "    print (token.i,                 # index of the token within the parent document\n",
    "           token,\n",
    "           token.text,               # verbatim text\n",
    "           token.ent_type_,     # named entity type\n",
    "           spacy.explain(token.ent_type_),\n",
    "           token.lemma_,        # base form of the token, with no inflectional suffixes\n",
    "           token.pos_,             # coarse-grained part-of-speech\n",
    "            spacy.explain(token.pos_),\n",
    "           token.tag_,             # fine-grained part-of-speech\n",
    "            spacy.explain(token.tag_),\n",
    "           token.dep_,            # syntactic dependency relation\n",
    "           token.like_url,        # does the token resemble a URL\n",
    "           token.like_num,     # does the token represent a number? e.g. “10.9”, “10”, “ten”, etc\n",
    "           token.like_email,    # does the token resemble an email address\n",
    "           token.is_stop,         # is the token part of a “stop list”\n",
    "          token.is_alpha,\n",
    "          token.is_ascii,\n",
    "          token.is_digit,\n",
    "          token.is_lower,\n",
    "          token.is_upper,\n",
    "          token.is_title,\n",
    "          token.is_punct,\n",
    "          token.is_space,\n",
    "          token.is_currency\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9621542455456396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can make semantic similarity estimates based on word vectors.\n",
    "# the default estimate is cosine similarity, using an average of word vectors for the document.\n",
    "# it returns a scalar similarity score (higher is more similar).\n",
    "doc1 = nlp(\"I like oranges that are sweet.\")\n",
    "# print (doc1.vector) # doc vector is average of token vectors\n",
    "doc2 = nlp(\"I like apples that are sour.\")\n",
    "# print (doc2.vector) # doc vector is average of token vectors\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amy go class', 'matt have lunch']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processing large corpuses with nlp.pipe\n",
    "\n",
    "# let's say you had a very large corpus of text\n",
    "# illustrated with a very small corpus below :)\n",
    "data = [\"Amy is going to class now.\",\n",
    "          \"Matt is having lunch.\"]\n",
    "\n",
    "# first, you'll only want to apply the pipeline components you need:\n",
    "# getting predictions from the model that you don’t actually need adds up and becomes very inefficient at scale. \n",
    "# to prevent this, use the disable keyword argument to disable components you don’t need.\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# and second, you'll want to work on batches of texts.\n",
    "# this can be done with spaCy’s nlp.pipe method which takes an iterable of texts and yields processed Doc objects. \n",
    "# the batching is done internally.\n",
    "corpus = nlp.pipe(data)\n",
    "\n",
    "# now we can clean the corpus efficiently\n",
    "def custom_tokenizer(doc):\n",
    "    tokens = [token.lemma_.lower() \n",
    "                      for token in doc \n",
    "                          if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
